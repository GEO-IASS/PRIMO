\section{Approximate Inference}
\subsection{Motivation}
\begin{frame}
\Large\textbf{Why use approximate Inference?}
  \begin{itemize}
   \item Possible to include non-linear dependencies of/on real-valued variables
   \item Only local computations $\rightarrow$ size of net rather unimportant
   \item Possible to trade off computation time for accuracy
  \end{itemize}
\end{frame}

\subsection{Structure}
  \begin{frame}
  \Large\textbf{Whats the stucture?}
    \begin{block}{There are two central classes for computation:}
      \begin{itemize}
       \item MCMC - Interface for usage, final computations
	\item MarkovChainSampler - Constructs markov chains
      \end{itemize}

    \end{block}

  \begin{block}{Other classes:}
   \begin{itemize}
    \item Evidence
  \item ContinuousNode (and densities: Gauss, Exponential, Beta)
   \end{itemize}

  \end{block}



  \end{frame}

  \begin{frame}
    \Large\textbf{MarkovChainSampler}
    generates a markov-chain given some evidence when chain has converged
    \begin{block}{Parameters}
      \begin{itemize}
	\item transition\_model: Gibbs or MetropolisHastings
	\item convergence\_test: Test for convergence
	\item time\_steps: Maximum length of chain
	\item evidence: Different kinds of evidence for a subset of nodes
      \end{itemize}
    \end{block}

\end{frame}
  \begin{frame}
    \Large\textbf{MCMC}
    Danach in MCMC klasse ergebnisse berechnen
\end{frame}
  \begin{frame}
    \Large\textbf{Real-valued variables}
      Which kinds of nodes are there?
	Gaussian, Beta, Exponential
\end{frame}
\subsection{Literature}
asdf